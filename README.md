# VideoGen-of-Thought
Official Implementation of VideoGen-of-Thought

# Outline
- [Introduction](#introduction)
- [Pipeline Details](#pipeline-details)
- [Usage](#usage)
- [Results](#results)
- [Citation](#citation)
- [TODO](#todo)
- [Acknowledgements](#acknowledgements)


# Introduction

VideoGen-of-Thought is a video generation model that generates videos based on text input. The model is based on the transformer-based architecture, which is a powerful sequence-to-sequence model that can handle long-term dependencies in the input sequence. The model is trained on a large-scale dataset of video-text pairs, and can generate high-quality videos with natural language descriptions.